{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['신', '은'], ['은', ' '], [' ', '다'], ['다', '시'], ['시', ' '], [' ', '일'], ['일', '어'], ['어', '서'], ['서', '는'], ['는', ' '], [' ', '법'], ['법', '을'], ['을', ' '], [' ', '가'], ['가', '르'], ['르', '치'], ['치', '기'], ['기', ' '], [' ', '위'], ['위', '해'], ['해', ' '], [' ', '넘'], ['넘', '어'], ['어', '뜨'], ['뜨', '린'], ['린', '다'], ['다', '고'], ['고', ' '], [' ', '나'], ['나', '는'], ['는', ' '], [' ', '믿'], ['믿', '는'], ['는', '다'], ['다', '.'], ['.']]\n",
      "[['신은', '다시', '일어서는'], ['다시', '일어서는', '법을'], ['일어서는', '법을', '가르치기'], ['법을', '가르치기', '위해'], ['가르치기', '위해', '넘어뜨린다고'], ['위해', '넘어뜨린다고', '나는'], ['넘어뜨린다고', '나는', '믿는다.'], ['나는', '믿는다.'], ['믿는다.']]\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"신은 다시 일어서는 법을 가르치기 위해 넘어뜨린다고 나는 믿는다.\"\n",
    "def word_ngram(sentence, num_gram):\n",
    "    ngrams = []\n",
    "    text = list(sentence) # split the sentence into an array of characters\n",
    "    ngrams = [text[x:x+num_gram] for x in range(0, len(text))]\n",
    "    return ngrams\n",
    "def phoneme_ngram(sentence, num_gram):\n",
    "    ngrams = []\n",
    "    text = sentence.split(' ')\n",
    "    ngrams = [text[x:x+num_gram] for x in range(0, len(text))]\n",
    "    return ngrams\n",
    "print(word_ngram(sample_text, 2))\n",
    "print(phoneme_ngram(sample_text, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국내', 'NNG'),\n",
       " ('크레딧', 'NNG'),\n",
       " ('워크아웃', 'NNG'),\n",
       " ('워크아웃', 'NNG'),\n",
       " ('파급효과', 'NNG'),\n",
       " ('워크아웃', 'NNG'),\n",
       " ('실물', 'NNG'),\n",
       " ('금융', 'NNG'),\n",
       " ('부문', 'NNG'),\n",
       " ('충격', 'NNG')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import kss\n",
    "from ekonlpy.tag import Mecab\n",
    "\n",
    "reportlist = pd.read_csv(\"pdf_link_crawl_add_txt.csv\", sep='\\t')\n",
    "\n",
    "def txt2filtered(self):\n",
    "    sents = kss.split_sentences(self)\n",
    "    sents = [sent.replace('\\n','') for sent in sents]\n",
    "    all_filtered_tokens = []\n",
    "    for sent in sents:\n",
    "        tokenizer = Mecab()\n",
    "        tokens = tokenizer.pos(sent)\n",
    "        filtered_tokens = []\n",
    "        for token in tokens:\n",
    "            if token[1] in ['NNG', 'VA', 'VAX','MAG','VA']:\n",
    "                filtered_tokens.append(token)\n",
    "        all_filtered_tokens.append(filtered_tokens)\n",
    "    return all_filtered_tokens\n",
    "\n",
    "dir = './reporttxt/'\n",
    "file_path = dir + reportlist['content_file'][0]\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "    filtered_tokens = txt2filtered(content)\n",
    "filtered_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'워크아웃': 3, '국내': 1, '크레딧': 1, '파급효과': 1, '실물': 1, '금융': 1, '부문': 1, '충격': 1})\n",
      "국내 크레딧 워크아웃 워크아웃 파급효과 워크아웃 실물 금융 부문 충격\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import zip_longest\n",
    "\n",
    "words = [filtered_tokens[0][i][0] for i in range(len(filtered_tokens[0]))]\n",
    "word_count = Counter(words)\n",
    "print(word_count)\n",
    "sent = ' '.join(i for i in words)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'국내 크레딧 워크아웃 워크아웃 파급효과 워크아웃 실물 금융 부문 충격 국내 크레딧'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent + ' 국내 ' + '크레딧'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BOKproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
